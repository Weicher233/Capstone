{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d14d24-8e39-4adf-a775-f915eb9c98cf",
   "metadata": {},
   "source": [
    "# Traffic trends for London's public transport network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db3e7e0-de78-448b-a8cd-0a60d51238f8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### 1.1 Background\n",
    "London is a global hub for large-scale events, hosting concerts, sports tournaments, cultural festivals, and more. These events significantly impact the city's transportation system, particularly the London Underground (TfL network).  \n",
    "\n",
    "Transport for London (TfL) typically schedules services based on historical data and pre-planned timetables. However, this method may not immediately accommodate fluctuations in passenger demand caused by events  \n",
    "\r\n",
    "Our study aims to analyze whether events can serve as a reliable predictor of station business (passenger flow) and assess how well TfL’s current scheduling aligns with demand surge  \n",
    "### 1.2 Research question  \n",
    "What key factors (e.g., event characteristics, external conditions) are most relevant in predicting station business during events?  \n",
    "H1: The type, scale, and ticketing status of an event have a significant impact on station business, but the extent of this impact varies depending on external factors such as weather, time, and competing events.\n",
    "\n",
    "\n",
    "Can we develop a tool that links event type, size, and scale with station business to improve network management?  \n",
    "H2: Developing a predictive model that links event characteristics with station business will provide data-driven insights for network management, thereby enhancing transport planning efficiency.\n",
    "\n",
    "\n",
    "Can integrating event data into a predictive model improve TfL’s ability to optimize scheduling and resource allocation?  \n",
    "H3:Integrating event data (such as event type, scale, and timing) into the predictive model will enhance TfL’s ability to accurately schedule services during high-demand periods, reduce over-scheduling and resource waste, and optimize train frequencies and station operations.  \n",
    "### 1.3 Data sources  \n",
    "1.3.1 TFL data:ons.\r\n",
    "e：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e06ce-cd5f-450d-ae63-97752389eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89ea6e-8975-4c04-a75d-addccd3234b3",
   "metadata": {},
   "source": [
    "## Data preprocessing and Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb021c1-7145-49aa-91ed-37c999efbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"data/NBT23MON_outputs.xlsx\",\n",
    "    \"data/NBT23TWT_outputs.xlsx\",\n",
    "    \"data/NBT23FRI_outputs.xlsx\",\n",
    "    \"data/NBT23SAT_outputs.xlsx\",\n",
    "    \"data/NBT23SUN_outputs.xlsx\"\n",
    "]\n",
    "\n",
    "sheet_names = [\n",
    "    \"Link_Loads\",\n",
    "    \"Link_Frequencies\",\n",
    "    \"Station_Flows\",\n",
    "    \"Station_Entries\",\n",
    "    \"Station_Exits\"\n",
    "]\n",
    "\n",
    "data_frames = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    data_frames[file_path] = {}\n",
    "    for sheet in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, skiprows=2)\n",
    "        data_frames[file_path][sheet] = df\n",
    "\n",
    "#Adjust all numbers in all datafrmaes to round to integers\n",
    "for file_path in data_frames:\n",
    "    for sheet in data_frames[file_path]:\n",
    "        data_frames[file_path][sheet] = data_frames[file_path][sheet].map(\n",
    "            lambda x: round(x) if isinstance(x, (float, int)) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e34848-15b9-4d4b-a8d1-320bf9f3e7bc",
   "metadata": {},
   "source": [
    "### 2.2 Webcraping  \n",
    "The following code block is used to get the location of stations for tube, dlr, overground and elizabeth-line.\n",
    "You need to have a .env file with APP_KEY in the same directory as this script.\n",
    "APP_KEY is the api key for the TfL API. See https://api-portal.tfl.gov.uk/ for more information.  \n",
    "The location of the stations consists of latitude and longitude using WGS84 coordinate system.\n",
    "The location and other information of the stations are saved in a csv file\n",
    "named stations_location.csv in the data folder for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b94ee0-5ae8-4a8f-95a0-c2928f4e92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "APP_KEY = os.getenv(\"APP_KEY\")\n",
    "\n",
    "def get_line_ids() -> dict[str, tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Get the line ids for tube, dlr, overground and elizabeth-line\n",
    "    :return: a dictionary with line id as key and line name and mode name as value\n",
    "    \"\"\"\n",
    "    url_line = \"https://api.tfl.gov.uk/Line/Route\"\n",
    "    params = {\n",
    "        \"app_key\": APP_KEY,\n",
    "    }\n",
    "    response = requests.get(url_line, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    mode_insterested = [\"tube\", \"dlr\", \"overground\", \"elizabeth-line\"]\n",
    "    line_ids = dict()\n",
    "    for line in data:\n",
    "        if line[\"modeName\"] in mode_insterested:\n",
    "            line_ids[line[\"id\"]] = (line[\"name\"], line[\"modeName\"])\n",
    "\n",
    "    return line_ids\n",
    "\n",
    "def get_station_stop_points(line_id_: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get the stop points for a given line\n",
    "    :param line_id_: the line id\n",
    "    :return: a list of stop points\n",
    "    \"\"\"\n",
    "    url_stop_points = f\"https://api.tfl.gov.uk/Line/{line_id_}/StopPoints\"\n",
    "    params = {\n",
    "        \"app_key\": APP_KEY,\n",
    "    }\n",
    "    response = requests.get(url_stop_points, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def get_station_stop_points_df() -> pd.DataFrame:\n",
    "    lines = get_line_ids()\n",
    "    stop_points_all = list()\n",
    "\n",
    "    for line_id, (line_name, mode_name) in lines.items():\n",
    "        stop_points = get_station_stop_points(line_id)\n",
    "        for stop_point in stop_points:\n",
    "            stop_points_all.append({\n",
    "                \"line_id\": line_id,\n",
    "                \"line_name\": line_name,\n",
    "                \"mode_name\": mode_name,\n",
    "                \"station_id\": stop_point[\"id\"],\n",
    "                \"station_name\": stop_point[\"commonName\"],\n",
    "                \"lat\": stop_point[\"lat\"],\n",
    "                \"lon\": stop_point[\"lon\"],\n",
    "                \"station_modes\": stop_point[\"modes\"]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(stop_points_all)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(\"data/stations_location.csv\"):\n",
    "        get_station_stop_points_df = get_station_stop_points_df()\n",
    "        get_station_stop_points_df.to_csv(\"data/stations_location.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
