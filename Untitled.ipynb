{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d14d24-8e39-4adf-a775-f915eb9c98cf",
   "metadata": {},
   "source": [
    "# Traffic trends for London's public transport network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6c07c-e90c-43d8-a68a-02539fab738e",
   "metadata": {},
   "source": [
    "![TFL MAP](https://tfl.gov.uk/cdn/static/cms/images/london-rail-and-tube-services-map.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db3e7e0-de78-448b-a8cd-0a60d51238f8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### 1.1 Background\n",
    "\n",
    "London's complex public transportation system serves millions of passengers daily and includes a wide range of bus routes and underground stations. However, accessibility remains a critical concern, especially for individuals with mobility impairments. To evaluate the inclusiveness of this network, we propose using an agent-based model to assess the accessibility of public transport in London, with a specific focus on **step-free access**.\n",
    "\n",
    "As an initial step, we merge the bus stop location dataset with the tube station location dataset, appending two new columns to record the names of all bus and tube stops within a 0.5-mile radius for each station. Following this spatial augmentation, we incorporate footfall data to assign weightings to each station based on passenger volume. We then utilize Monte Carlo simulations to model popular travel routes across the network.\n",
    "\n",
    "Under the constraint of considering **only step-free stations**, we preliminarily evaluate whether a given origin-destination (OD) pair has a feasible route. Routes are labeled as \"1\" if a step-free path exists, and the number of interchanges is recorded; otherwise, they are labeled as \"0.\" For all accessible OD pairs (label = 1), we apply shortest path algorithms to compute minimal distance or travel time, allowing us to identify routes that, while accessible, are inefficient compared to the average.\n",
    "\n",
    "Our final analysis targets two categories of concern: (1) **inaccessible OD pairs** (label = 0), and (2) **inefficient but accessible routes** (label = 1 with high cost). We trace these routes to identify critical interruption points and evaluate their frequency and crowd density. These stations are then prioritized for potential infrastructure upgrades, such as new bus stop installations or transfer improvements.\n",
    "\n",
    "### 1.2 Research Questions\n",
    "\n",
    "- How accessible is London’s public transport system for mobility-impaired passengers, considering only step-free routes?\n",
    "- Can we identify high-demand routes that are either inaccessible or significantly inefficient for step-free travel?\n",
    "- What are the key transfer stations or segments that contribute to poor accessibility, and how can infrastructure investment be prioritized accordingly?\n",
    "\n",
    "### 1.3 Data Sources\n",
    "\n",
    "**1.3.1 Footfall Data**  \n",
    "- Source:  \n",
    "  https://app.powerbi.com/view?r=eyJrIjoiMjZjMmQwYTktZjYxNS00MTIwLTg0ZjAtNWIwNGE0ODMzZGJhIiwidCI6IjFmYmQ2NWJmLTVkZWYtNGVlYS1hNjkyLWEwODljMjU1MzQ2YiIsImMiOjh9\n",
    "  or https://crowding.data.tfl.gov.uk/Network%20Demand/StationFootfall_2023_2024%20.csv  \n",
    "- Description: Historical station-level passenger flow data from the London Underground (TfL)\n",
    "\n",
    "**1.3.2 Station Location Data**  \n",
    "- Bus Stop Locations: https://data.london.gov.uk/dataset/tfl-bus-stop-locations-and-routes \n",
    "- Tube Station Locations: https://foi.tfl.gov.uk/FOI-2209-2122/Station%20locations.csv  \n",
    "\n",
    "**1.3.3 Accessibility Data**  \n",
    "- Step-free Access Information: https://content.tfl.gov.uk/step-free-tube-guide-map.pdf  \n",
    "- Note: Additional data sources will be explored to supplement this guide and ensure comprehensive coverage of accessibility infrastructure.\n",
    "e：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3e06ce-cd5f-450d-ae63-97752389eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89ea6e-8975-4c04-a75d-addccd3234b3",
   "metadata": {},
   "source": [
    "## Tube Data preprocessing and Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb021c1-7145-49aa-91ed-37c999efbe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TravelDate', 'DayOFWeek', 'Station', 'EntryTapCount', 'ExitTapCount'], dtype='object')\n",
      "Index(['TravelDate', 'DayOFWeek', 'Station', 'EntryTapCount', 'ExitTapCount'], dtype='object')\n",
      "Index(['TravelDate', 'DayOFWeek', 'Station', 'EntryTapCount', 'ExitTapCount'], dtype='object')\n",
      "Index(['TravelDate', 'DayOFWeek', 'Station', 'EntryTapCount', 'ExitTapCount'], dtype='object')\n",
      "Index(['TravelDate', 'DayOfWeek', 'Station', 'EntryTapCount', 'ExitTapCount'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_paths = [\n",
    "    \"data/StationFootfall_2019.csv\",\n",
    "    \"data/StationFootfall_2020.csv\",\n",
    "    \"data/StationFootfall_2021.csv\",\n",
    "    \"data/StationFootfall_2022.csv\",\n",
    "    \"data/StationFootfall_2023_2024 .csv\"\n",
    "]\n",
    "\n",
    "tfl_list = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    print(df.columns)\n",
    "    tfl_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1347c4c-580b-4db6-9f98-fc5ae8e6395a",
   "metadata": {},
   "source": [
    "## Bus Data Acquisition via TfL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9774a-6143-4741-86af-f7f3940f38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "all_stops = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    url = f'https://api.tfl.gov.uk/StopPoint/Mode/bus?page={page}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'stopPoints' not in data or not data['stopPoints']:\n",
    "        break\n",
    "\n",
    "    for stop in data['stopPoints']:\n",
    "        all_stops.append({\n",
    "            'id': stop.get('id'),\n",
    "            'naptanId': stop.get('naptanId'),\n",
    "            'commonName': stop.get('commonName'),\n",
    "            'lat': stop.get('lat'),\n",
    "            'lon': stop.get('lon'),\n",
    "            'modes': ', '.join(stop.get('modes', [])),\n",
    "            'lines': ', '.join([l['name'] for l in stop.get('lines', [])])\n",
    "        })\n",
    "\n",
    "    print(f'Page {page} fetched — {len(all_stops)} bus stops in total.')\n",
    "    page += 1\n",
    "\n",
    "df = pd.DataFrame(all_stops)\n",
    "display(df.head())\n",
    "df.to_csv('latest_bus_stops.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a035ca-0ae1-4125-872f-57dae61173ce",
   "metadata": {},
   "source": [
    "### Bus Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82130430-6617-42af-8095-55abe11d9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = df['lines'].isna().sum()\n",
    "print(f'Total missing lines: {missing_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662b1a4-92dd-458e-83dc-3e464ac2f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the DataFrame that indicates whether the stop is served by buses only.\n",
    "df['is_pure_bus'] = df['modes'].apply(lambda x: x.strip() == 'bus').map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cead305-fa26-474b-b7b1-77984f69329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "def clean_lines(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    lines = [l.strip() for l in text.split(',')]\n",
    "    return ', '.join(sorted(set(lines)))\n",
    "\n",
    "df['lines'] = df['lines'].apply(clean_lines)\n",
    "\n",
    "df['commonName'] = df['commonName'].str.lstrip('.').str.strip()\n",
    "df['lines'] = df['lines'].apply(clean_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb0128-6b11-44bb-abca-55fabf9e27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "def merge_lines(series):\n",
    "    all_lines = []\n",
    "    for line_list in series:\n",
    "        all_lines.extend([l.strip() for l in line_list.split(',') if l.strip()])\n",
    "    return ', '.join(sorted(set(all_lines)))\n",
    "\n",
    "grouped_df = df.groupby(['commonName', 'lat', 'lon','is_pure_bus']).agg({\n",
    "    'id': 'first',\n",
    "    'lines': merge_lines\n",
    "    }).reset_index()\n",
    "\n",
    "display(grouped_df.head())\n",
    "grouped_df.to_csv('processed_bus_stops.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e34848-15b9-4d4b-a8d1-320bf9f3e7bc",
   "metadata": {},
   "source": [
    "### 2.2 Webcraping  \n",
    "The following code block is used to get the station location of the metro. It will need to create an .env file with APP_KEY in the same directory as this script.APP_KEY is the api key for the TfL API. See https://api-portal.tfl.gov.uk/ for more information.\r\n",
    "The site location includes latitude and longitude using the WGS84 coordinate system. The location of the stations and other information is saved in a csv file named stations_location.csv in the data folder for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626d779f-405f-4846-9dcf-bfeb4ef4ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_ID= \"crowding\"\n",
    "APP_KEY = \"0a2ad06e04f243b2a3a0cdbf8c62e314\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1231ce5-58f9-4847-84a5-67d7acc56fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metro station location information has been saved to data/stations_location.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "APP_ID = os.getenv(\"APP_ID\")\n",
    "APP_KEY = os.getenv(\"APP_KEY\")\n",
    "\n",
    "def get_line_ids() -> dict[str, tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Gets the routing information for all lines and filters out the tube, dlr, overground and elizabeth-line modes.\n",
    "    Returns a dictionary with line id as key and (line name, mode name) as value.\n",
    "    \"\"\"\n",
    "    url_line = \"https://api.tfl.gov.uk/Line/Route\"\n",
    "    params = {\n",
    "        \"app_id\": APP_ID,\n",
    "        \"app_key\": APP_KEY,\n",
    "    }\n",
    "    response = requests.get(url_line, params=params)\n",
    "    response.raise_for_status()  \n",
    "    data = response.json()\n",
    "\n",
    "    mode_interested = [\"tube\", \"dlr\", \"overground\", \"elizabeth-line\"]\n",
    "    line_ids = {}\n",
    "    for line in data:\n",
    "        if line.get(\"modeName\") in mode_interested:\n",
    "            line_ids[line[\"id\"]] = (line[\"name\"], line[\"modeName\"])\n",
    "    return line_ids\n",
    "\n",
    "def get_station_stop_points(line_id: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get all stations on a line by line id.\n",
    "    :param line_id: line id\n",
    "    :return: list of stations\n",
    "    \"\"\"\n",
    "    url_stop_points = f\"https://api.tfl.gov.uk/Line/{line_id}/StopPoints\"\n",
    "    params = {\n",
    "        \"app_id\": APP_ID,\n",
    "        \"app_key\": APP_KEY,\n",
    "    }\n",
    "    response = requests.get(url_stop_points, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_station_stop_points_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the information of all the stations under the line of interest and construct a DataFrame.\n",
    "    \"\"\"\n",
    "    lines = get_line_ids()\n",
    "    stop_points_all = []\n",
    "    \n",
    "    for line_id, (line_name, mode_name) in lines.items():\n",
    "        try:\n",
    "            stop_points = get_station_stop_points(line_id)\n",
    "            for sp in stop_points:\n",
    "                stop_points_all.append({\n",
    "                    \"line_id\": line_id,\n",
    "                    \"line_name\": line_name,\n",
    "                    \"mode_name\": mode_name,\n",
    "                    \"station_id\": sp.get(\"id\", \"\"),\n",
    "                    \"station_name\": sp.get(\"commonName\", \"\"),\n",
    "                    \"lat\": sp.get(\"lat\", \"\"),\n",
    "                    \"lon\": sp.get(\"lon\", \"\"),\n",
    "                    \"station_modes\": sp.get(\"modes\", []),\n",
    "                })\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to get station information for line {line_id}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(stop_points_all)\n",
    "\n",
    "def save_station_locations(file_path: str = \"data/stations_location.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Get station location information and save it to a CSV file\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    \n",
    "    df = get_station_stop_points_df()\n",
    "    df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Metro station location information has been saved to {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        save_station_locations()\n",
    "    except Exception as e:\n",
    "        print(\"Error during programme execution：\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff9918-e43f-4626-b19d-766c1ac95bc5",
   "metadata": {},
   "source": [
    "The following code block matches the station names in the TfL data with the station names in the location data. Matched data are saved in tfl_stations_location.csv for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "838ec3f1-cf73-4d39-a14d-9f5376a7b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matched data has been saved to the tfl_stations_location.csv\n"
     ]
    }
   ],
   "source": [
    "tfl_df = pd.concat(tfl_list, ignore_index=True)\n",
    "\n",
    "# Pre-processing of station names for subsequent matching: removal of spaces, conversion to lower case\n",
    "tfl_df[\"Station_clean\"] = tfl_df[\"Station\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "location_file = \"data/stations_location.csv\"\n",
    "location_df = pd.read_csv(location_file)\n",
    "\n",
    "# The station names in the location data are also preprocessed\n",
    "location_df[\"station_name_clean\"] = location_df[\"station_name\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Merge based on preprocessed columns\n",
    "merged_df = pd.merge(\n",
    "    tfl_df,\n",
    "    location_df,\n",
    "    left_on=\"Station_clean\",\n",
    "    right_on=\"station_name_clean\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "output_file = \"tfl_stations_location.csv\"\n",
    "merged_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"The matched data has been saved to the {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e817b716-fc23-47c7-a51d-5b5b9a8cb00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data have been merged and saved to merged_stations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Dataset\n",
    "bus_stops_df = pd.read_csv('data/processed_bus_stops.csv')\n",
    "stations_location_df = pd.read_csv('data/stations_location.csv')\n",
    "\n",
    "# Data preprocessing: clean-up and harmonization of site name formats\n",
    "bus_stops_df[\"commonName_clean\"] = bus_stops_df[\"commonName\"].str.strip().str.lower()\n",
    "stations_location_df[\"station_name_clean\"] = stations_location_df[\"station_name\"].str.strip().str.lower()\n",
    "\n",
    "# Merge data based on processed site names\n",
    "merged_df = pd.merge(\n",
    "    bus_stops_df,\n",
    "    stations_location_df,\n",
    "    left_on=\"commonName_clean\",\n",
    "    right_on=\"station_name_clean\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "merged_df.to_csv('data/merged_stations.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Data have been merged and saved to merged_stations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e69e9-22b7-4c2d-b18c-2c7c410020fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
